# Sensor Physics Research Documentary

**Iterative Research Document â€” Physical Fidelity of Sensor Simulation**

This document is built through 4 iterations of reflection, online research, and self-correction. Each iteration refines, challenges, and strengthens the reasoning. The goal: understand every physical phenomenon a digital image sensor encounters, assess our current shader implementation against true physical reality, and document what would be required for a fully faithful simulation.

---

## Revision Log

| Iteration | Date | Focus |
|-----------|------|-------|
| 1 | 2026-02-10 | Initial reflected thoughts from first principles |
| 2 | 2026-02-10 | EMVA 1288 corrections, Arrhenius model, PRNU wavelength, 1/f noise + CDS |
| 3 | 2026-02-10 | Cosmic ray rates, pixel crosstalk, RTS noise, MHC details, PTC method, dead pixels |
| 4 | 2026-02-10 | Pipeline order confirmation, blooming physics, real sensor data, final synthesis |

---

# Part 1: RGB to Bayer â€” The Fundamental Misunderstanding

## 1.1 What a Sensor Actually Sees

A digital image sensor does **not** see colour. Each photosite is a monochrome light bucket â€” it counts photons via the photoelectric effect and reads out a single scalar value: a charge count.

To capture colour, a **Colour Filter Array (CFA)** is placed over the sensor. The most common is the **Bayer pattern** (Bryce Bayer, Kodak, 1976):

```
Row 0:  R  G  R  G  R  G  ...
Row 1:  G  B  G  B  G  B  ...
Row 2:  R  G  R  G  R  G  ...
Row 3:  G  B  G  B  G  B  ...
```

Each 2Ã—2 superpixel: 1R, 2G, 1B. Green is doubled because human vision peaks at ~555 nm.

**Key realisation**: At the raw sensor level, each pixel has only ONE value. A red-filtered pixel receives white light but only measures the red component.

## 1.2 RGB to Bayer: The Reverse Operation

In shader simulation, we start with RGB (3 values/pixel) and convert to Bayer (1 value/pixel):

```glsl
int x = int(fragCoord.x) % 2;
int y = int(fragCoord.y) % 2;

float bayerValue;
if (x == 0 && y == 0)      bayerValue = color.r;  // Red
else if (x == 1 && y == 1)  bayerValue = color.b;  // Blue
else                         bayerValue = color.g;  // Green
```

Implications:
1. **Information loss**: 3 channels â†’ 1. Two-thirds of colour data discarded (physically correct).
2. **Mosaic image**: Single-channel, finely patterned grey image with subtle colour cast.
3. **Demosaicing required**: Must reconstruct missing channels via interpolation.

## 1.3 Why Bayer Matters for Noise Simulation

Our current shaders operate in RGB space. What we miss:

| Gap | Description | Visual Impact |
|-----|-------------|---------------|
| Noise spatial correlation | Demosaicing spreads single-pixel noise â†’ correlated colour blobs, not speckle | **High** |
| Green channel advantage | 2G per quad â†’ better green SNR; our RGB treats all channels equally | Medium |
| Aliasing / moirÃ© | Bayer undersamples ~2Ã— per channel; fine details can false-colour | Medium |
| Colour noise character | Real noise is "splotchy" from demosaic; ours is random per-channel speckle | **High** |

## 1.4 The Correct Pipeline Order

**Iteration 4 â€” Confirmed by research**: Noise MUST be applied in the **Bayer domain** (before demosaicing) for physical accuracy. This is the standard approach in all sensor simulation literature (Stanford ISETCam, CVPR papers, IISW proceedings).

```
Rendered RGB Scene
    â†“
[1. Bayer Mosaic Shader] â€” select one channel per pixel based on position
    â†“
[2. Apply ALL noise in mosaic domain] â€” shot, dark current, DSNU, PRNU, read noise
    â†“
[3. Quantisation (ADC)] â€” convert to integer domain
    â†“
[4. Demosaicing Shader (MHC)] â€” reconstruct RGB
    â†“
[5. ISP] â€” white balance, CCM, gamma, NR, sharpening
    â†“
Display
```

**Why this order matters**: When noise is applied per-photosite (scalar value) and then demosaiced, the interpolation creates spatial correlations in the RGB output that perfectly match real camera noise character. Applying noise in RGB space after demosaicing gives the wrong correlation structure.

**For our current shaders**: We can continue using the RGB-domain approach as a "good enough" approximation, but the document should make clear this is a known simplification. A physically correct implementation would restructure the pipeline as above.

## 1.5 Malvar-He-Cutler â€” The GPU Demosaicing Algorithm

**Confirmed across all iterations**: MHC is the definitive choice for GPU demosaicing.

**Algorithm**: 8 distinct 5Ã—5 linear filters for each combination of interpolated channel + pixel position. Each is bilinear interpolation + gradient corrections (Laplacians from neighbouring channels).

**Performance (Morgan McGuire, 2008)**:
- **40 simultaneous HD 1080p streams at 30 fps** (2728 Mpix/s)
- 2-3Ã— faster than unoptimized GLSL
- Integer arithmetic with /16 via bitshifting
- Only **13 texture samples** per pixel (sparse 5Ã—5 kernel)

**Implementation sketch**:
```glsl
// Optimized MHC: branch-free via swizzle selection
ivec2 pos = ivec2(fragCoord) % 2;  // Bayer position
// 4 possible (x,y) combinations select different coefficient sets
// Apply 5x5 convolution using 13 texture samples
// Result >> 4 (divide by 16)
```

## 1.6 Bayer Pattern Variations

| Pattern | Size | Used By | Notes |
|---------|------|---------|-------|
| RGGB/GRBG/GBRG/BGGR | 2Ã—2 | 90%+ of sensors | Rotated Bayer variants |
| RGBW | 2Ã—2 | Sony, Aptina | Clear pixel for low-light |
| X-Trans | 6Ã—6 | Fujifilm | Reduced moirÃ© without OLPF |
| Foveon | 3 layers | Sigma | Full RGB per site |
| Quad Bayer | 4Ã—4 | Samsung, Sony | 2Ã—2 binning in low light |

## 1.7 CFA Spectral Imperfection

Real Bayer filters don't have ideal bandpass responses â€” the red filter transmits some green and NIR. Our `bayerValue = color.r` assumes perfect separation. This matters for:
- NIR contamination (vegetation red edge at ~750 nm)
- Line spectra (LEDs, sodium lamps)
- Spectral metamerism

For general simulation: acceptable. For spectral accuracy: need multispectral rendering.

---

# Part 2: Dark Noise Taxonomy â€” Precise Definitions

## 2.1 The Complete Hierarchy

```
Dark Signal (total in darkness)
â”œâ”€â”€ Dark Current (deterministic mean, f(T, t_exp))
â”‚   â”œâ”€â”€ Dark Current Shot Noise (Poisson temporal variation)
â”‚   â””â”€â”€ Dark Current Drift (long-term evolution)
â”œâ”€â”€ DSNU (spatial per-pixel variation, fixed-pattern)
â”‚   â”œâ”€â”€ Hot Pixels (extreme outliers)
â”‚   â””â”€â”€ Dead Pixels (zero response)
â”œâ”€â”€ Dark Signal Offset (electronic pedestal)
â””â”€â”€ 1/f Component (slow temporal baseline fluctuation)
```

## 2.2 Dark Current (Signal, Not Noise)

Steady thermal electron generation, independent of light.

| Property | Value |
|----------|-------|
| Cause | Thermally generated eâ»-hâº pairs (depletion region + Si-SiOâ‚‚ interface) |
| T dependence | Arrhenius: doubles every ~5-10Â°C |
| Unit | eâ»/pixel/s |

**Iteration 4 â€” Typical Values for Simulation Targets**:

| Sensor Category | Dark Current (25Â°C) | Read Noise | Notes |
|----------------|---------------------|------------|-------|
| Scientific cooled CCD (-40Â°C) | 0.001 eâ»/px/s | 2-5 eâ» | Best case, thermoelectrically cooled |
| Scientific sCMOS (air-cooled) | 0.55 eâ»/px/s | 1-3 eâ» | e.g., Hamamatsu ORCA |
| Consumer DSLR/mirrorless | 0.5-5 eâ»/px/s | 2-8 eâ» | Canon, Sony, Nikon at room temp |
| DJI Drone (1/1.3" CMOS) | ~1 eâ»/px/s | 2-5 eâ» | Estimated from sensor class |
| Smartphone (high T, small pixel) | 5-50 eâ»/px/s | 3-10 eâ» | Higher due to small px + warm |
| Automotive (40-85Â°C operating) | 10-100+ eâ»/px/s | 5-15 eâ» | High temp â†’ high dark current |
| Camera module (generic) | <1 eâ»/px/s at 25Â°C | - | OmniVision, Sony IMX spec |

**Key takeaway**: Our shader parameter `u_darkCurrentBase` should default to ~1-5 eâ»/px/s equivalent for typical consumer sensors. Automotive simulation would use 10-100Ã— higher values.

## 2.3 Dark Current Shot Noise (Temporal)

Poisson(Î»_dark). Ïƒ = âˆšÎ»_dark. Changes every frame. Depends on T and t_exp, not scene.

## 2.4 DSNU (Fixed Pattern, Not "Noise")

Spatial variation of dark current across pixels. EMVA 1288 deliberately uses **"non-uniformity"** â€” DSNU is deterministic, repeatable, calibratable. Our spatial-seed approach correctly models this.

## 2.5 "Dark Noise" â€” EMVA 1288 Definition

**Ïƒ_d (temporal dark noise)** = total temporal noise in darkness = ÏƒÂ²_dark_shot + ÏƒÂ²_read + ÏƒÂ²_quant + ÏƒÂ²_1/f + ...

At short exposure: Ïƒ_d â‰ˆ Ïƒ_read. At long exposure: Ïƒ_d â‰ˆ âˆš(ÏƒÂ²_read + Î»_dark).

**Our shader separation** (dark_noise.frag + read_noise.frag) is more granular than EMVA 1288's single Ïƒ_d â€” this is a strength for simulation modularity.

## 2.6 Current Shader Assessment

| Aspect | Status | Notes |
|--------|--------|-------|
| DSNU (half-normal) | âœ… | Physically reasonable |
| Hot pixels (Bernoulli + spatial seed) | âœ… | Correct |
| Temporal dark current Poisson | âœ… | Correct |
| Dark current baseline | âœ… | Correct |
| `*1000.0/1000.0` scaling | âš ï¸ | Should use electron domain |
| Temperature dependence | âŒ | Arrhenius needed |
| Exposure time dependence | âŒ | Linear accumulation |
| Dead pixels | âŒ | Always-zero pixels |

## 2.7 Arrhenius Dark Current Model

```
I_dark(T) = I_0 Ã— exp(-Î”E / kT)
```

| Regime | Mechanism | Î”E | Doubling Temp |
|--------|-----------|-----|---------------|
| Low T (< ~20Â°C) | SRH depletion generation | Eg/2 â‰ˆ **0.56 eV** | ~5.8Â°C |
| High T (> ~40Â°C) | Diffusion current | Eg â‰ˆ **1.12 eV** | ~10Â°C |
| Interface states | Surface generation | **0.40 eV** | ~4Â°C |

**Meyer-Neldel Rule**: I_0 and Î”E are correlated across pixels â†’ an "isokinetic temperature" exists where all pixels have equal dark current. Consequence: DSNU distribution shape changes with temperature.

**Shader formula**:
```glsl
float dc_at_T = u_dcRef * exp(u_Ea / k_B * (1.0/T_ref - 1.0/T));
```

## 2.8 Dead Pixels

Missing from our simulation. Types:
- **Stuck low**: Always dark (damaged photodiode, blocked lens)
- **Stuck high**: Always at fixed bright value (adjacent to but distinct from hot pixels)

Prevalence: <0.001% (new sensor) â†’ 0.1%+ (aged/irradiated).

```glsl
if (rand_float(spatialState) < u_deadPixelRate)
    noisy = vec3(isStuckHigh ? u_stuckValue : 0.0);
```

---

# Part 3: Complete Physical Sensor Simulation

## 3.1 The Photon-to-Digital-Number Chain

```
Scene Spectral Radiance
    â†“ Atmospheric transmission (Beer-Lambert, Rayleigh, Mie)
    â†“ Optics (focal length, aperture, aberrations, vignetting, OLPF)
    â†“ IR cut filter
    â†“ Microlens array (fill factor enhancement)
    â†“ Colour filter array (Bayer mosaic)
    â†“ Photoelectric conversion (QE Ã— spectral response)
    â†“ Charge accumulation (+ dark current + crosstalk)
    â†“ PRNU (multiplicative per-pixel gain)
    â†“ Shot noise (Poisson on total signal)
    â†“ Charge overflow / blooming (if near FWC)
    â†“ Non-linear response (soft saturation near FWC)
    â†“ Pixel readout (source follower + CDS)
    â†“ Column amplifier (column FPN)
    â†“ Read noise + 1/f noise + RTS noise
    â†“ ADC (quantisation + DNL)
    â†“ ISP (black level, linearise, demosaic, WB, CCM, gamma, NR, sharp)
    â†“ Output Image
```

## 3.2 Environmental Prerequisites

### Light Sources
- **Solar SPD**: ~5778K blackbody with Fraunhofer lines
- **Atmospheric path**: Rayleigh (âˆÎ»â»â´), Mie, Hâ‚‚O/COâ‚‚/Oâ‚ƒ absorption
- **Time-of-day spectral shift**: Longer path â†’ redder spectrum

### Scene
- **BRDFs**: Angle-dependent reflectance
- **Spectral reflectance**: Not just RGB â€” full spectral curves (vegetation red edge at 750 nm)
- **Self-emission**, fluorescence

### Atmosphere
- Beer-Lambert exponential extinction
- Wavelength-dependent scattering
- Aerosol (haze, fog, dust)

## 3.3 Optics

| Element | Effect | Difficulty |
|---------|--------|-----------|
| Lens transmission | ~10% loss (10-element) | Easy (uniform multiply) |
| Lateral CA | Colour fringing at edges | Medium (per-channel UV offset) |
| Longitudinal CA | Colour fringing in defocus | Hard |
| Barrel/pincushion distortion | Geometric deformation | Medium (UV remap) |
| Natural vignetting | cosâ´(Î¸) falloff | Easy |
| Mechanical vignetting | Physical barrel clipping | Medium |
| Diffraction (Airy) | Resolution loss at small f/# | Hard (frequency domain) |
| Lens flare/ghosts | Internal reflections | Hard |
| IR-cut filter | Blocks >700 nm | Implicit in RGB |
| OLPF | Intentional blur for anti-moirÃ© | Medium (pre-filter) |

## 3.4 The Sensor

### Photoelectric Conversion
- **QE**: 50-80% peak (consumer), 90%+ (BSI scientific). Wavelength-dependent.
- **Fill factor**: 30-60% (front-illuminated), 80-95% (BSI)

### Charge Accumulation and Non-Linearity

**FWC**: 5,000â€“50,000 eâ» (consumer), 100,000+ (large pixels).

**Non-linearity near saturation** (confirmed in research):
- Conversion gain degradation: Floating diffusion capacitance is voltage-dependent
- Source follower non-linearity: gain varies with output voltage
- **Linear FWC** is ~70-85% of absolute saturation (EMVA 1288 evaluates lower 70%)

```glsl
float softSaturate(float signal, float fwc) {
    float linear_range = 0.85 * fwc;
    if (signal < linear_range) return signal;
    float excess = signal - linear_range;
    float knee = fwc - linear_range;
    return linear_range + knee * (1.0 - exp(-excess / knee));
}
```

### Blooming â€” Anti-Blooming Drain Physics

**Iteration 4 â€” New research on ABD mechanisms**:

When a pixel accumulates charge beyond its FWC, two things can happen:
1. **Without anti-blooming**: Excess charge diffuses into neighbouring pixels â†’ bright streaks/bleeding
2. **With anti-blooming drain (ABD)**: Excess charge is shunted to a drain

Two ABD architectures:
- **Lateral Overflow Drain (LOD)**: An overflow gate adjacent to the photodiode with a controlled potential barrier. When charge exceeds the barrier height, it flows laterally into a reverse-biased drain diode â†’ ground.
- **Vertical Overflow Drain (VOD)**: Drain beneath the photodiode. Excess charge flows vertically into the substrate. Uses epitaxial layer structure with controlled implant profiles.

**For simulation**: Modern CMOS sensors almost universally have anti-blooming structures. Blooming rarely occurs in well-designed sensors unless exposure is extremely overexposed (>100Ã— FWC). Our simulation can:
1. Default: Hard-clip at FWC (sufficient for most applications)
2. Advanced: Soft saturation curve (see above)
3. Full physics: Model charge overflow to 4 nearest neighbours (compute shader needed)

### Complete Noise Source Inventory

| # | Source | Distribution | Type | Status |
|---|--------|-------------|------|--------|
| 1 | Photon shot noise | Poisson(NÃ—QE) | Temporal, signal-dep | âœ… |
| 2 | Dark current (mean) | Deterministic | Systematic | âœ… |
| 3 | Dark current shot noise | Poisson(Î»_dark) | Temporal | âœ… |
| 4 | DSNU | Half-normal (spatial) | Fixed-pattern | âœ… |
| 5 | Hot pixels | Bernoulli + constant | Fixed-pattern | âœ… |
| 6 | PRNU | N(1, Ïƒ) gain | Fixed-pattern, multiplicative | âœ… |
| 7 | Read noise | N(0, Ïƒ_read) | Temporal | âœ… |
| 8 | **1/f noise** | 1/f spectrum | Temporal (correlated) | âŒ |
| 9 | **Column FPN** | N(0, Ïƒ_col) per column | Fixed-pattern | âŒ |
| 10 | **Quantisation** | Uniform Â±0.5 LSB | Systematic | âŒ |
| 11 | **RTS noise** | 2-state Markov | Temporal (discrete) | âŒ |
| 12 | **Dead pixels** | Zero/stuck value | Fixed-pattern | âŒ |
| 13 | **Pixel crosstalk** | Neighbour coupling | Spatial | âŒ |
| 14 | **Blooming** | Charge overflow | Signal-dep | âŒ |
| 15 | **Non-linearity** | Compression near FWC | Signal-dep | âŒ |
| 16 | **Cosmic ray hits** | Random bright events | Temporal (rare) | âŒ |
| 17 | **Row noise** | Per-row variation | Mixed | âŒ |

### 1/f Noise â€” Deep Analysis

**CDS does NOT eliminate 1/f noise** â€” it suppresses partially (high-pass filter), but 1/f remains dominant in many CIS.

Advanced techniques: CMS (multiple sampling), in-pixel chopping (~22 dB gain), buried-channel SF.

**Simulation**: Requires temporal state (persistent buffer or compute shader feedback).
- FFT: shape white noise as 1/f^Î±
- Random walk: Gaussian increment per frame â†’ ~1/fÂ² (Brownian, visually similar)
- Pre-generated library: cycle through temporally-correlated frames

### Column FPN

Vertical stripes. Two components:
- **Offset**: Signal-independent per-column offset (Ïƒ â‰ˆ 0.1-1% of full scale)
- **Gain**: Signal-dependent per-column gain variation

```glsl
uint colSeed = pcg_hash(uint(fragCoord.x) * 2654435761u + 12345u);
float colOffset = u_colFPN_offset * rand_normal_from(colSeed);
float colGain = 1.0 + u_colFPN_gain * rand_normal_from(pcg_hash(colSeed + 99991u));
color = color * colGain + vec3(colOffset);
```

### RTS (Random Telegraph Signal) Noise

Discrete switching caused by single charge traps at Si-SiOâ‚‚ interface.

**Prevalence**: 1-2% of pixels in modern sCMOS, up to 5% in some sensors. **Increasing with process shrink** (smaller transistors â†’ fewer traps but each trap has larger relative effect).

Not feasible in stateless fragment shader â€” needs persistent per-pixel state or precomputed RTS maps.

### Pixel Crosstalk

Two types:
- **Optical**: Diffraction/reflection from metal layers; worse at oblique angles
- **Electrical**: Lateral diffusion of photo-generated carriers; worse for NIR (deeper absorption)

Quantification: 1-5% optical + 2-10% electrical per neighbour (modern BSI sensors).

```glsl
float alpha = u_crosstalkFrac; // e.g. 0.02
vec3 result = center*(1.0-4.0*alpha) + alpha*(left+right+up+down);
```

### Cosmic Ray Hits

**HST (LEO) data**: 1.8 events/chip/s, ~6.7 pixels/event, ~3.8% of pixels in 2000s exposure.

| Environment | Rate | Notes |
|-------------|------|-------|
| Ground level | ~few/sensor/hour | Negligible for terrestrial |
| LEO | ~2 events/cmÂ²/min | Significant for long exposures |
| GEO / deep space | Higher | SAA and no geomagnetic shielding |
| CMOS in LEO (2 years) | ~0.1% permanent hot pixels | Cumulative damage |

## 3.5 Signal Processing Chain

### Photon Transfer Curve (PTC) â€” The Standard Characterisation Method

Plots **noiseÂ² vs. mean signal** across exposure levels:

```
                    PRNU-dominated (ÏƒÂ² âˆ SÂ²)
                   /
                  /
               Shot-noise-dominated (ÏƒÂ² âˆ S, slope=1 on log-log)
              /
             /
-----------    â† Read noise floor (ÏƒÂ² = const) 
                
0                                               Saturation
                     Mean Signal â†’
```

| Region | Reveals |
|--------|---------|
| Low signal (flat) | Read noise Ïƒ_read |
| Mid signal (slope 1) | Conversion gain K = 1/slope (eâ»/DN) |
| High signal (slope 2) | PRNU Ïƒ |
| Rollover | Full well capacity |
| Departure from slope 1 | Non-linearity onset (70-85% of FWC) |

**EMVA 1288 uses lower 70% of PTC** for parameter extraction.

**Validation strategy**: Generate synthetic PTC from our shader â†’ compare against real sensor datasheets.

### Full ISP Pipeline

```
Raw Bayer (eâ» â†’ ADC â†’ DN)
  â†“ Black level subtraction (remove dark pedestal)
  â†“ Linearisation (correct ADC non-linearity)
  â†“ Bad pixel correction (interpolate hot/dead)
  â†“ Flat-field correction (Ã· PRNU/vignetting map)
  â†“ Demosaicing (MHC â†’ RGB)
  â†“ White balance (per-channel multiply)
  â†“ CCM (3Ã—3 â†’ sRGB/AdobeRGB)
  â†“ Tone mapping / gamma (linear â†’ perceptual)
  â†“ Noise reduction (spatial/temporal)
  â†“ Sharpening (counter OLPF + demosaic softening)
  â†“ Compression (JPEG quantisation)
Final Image
```

## 3.6 Environmental Effects

| Factor | Effect | Simulation Level |
|--------|--------|-----------------|
| Temperature | Dark current Arrhenius, read noise âˆ âˆšT, QE shift | Medium (uniform) |
| Radiation (SEE) | Cosmic ray hits (instant bright dots) | Easy (Bernoulli) |
| Radiation (TID) | Cumulative dark current increase, new hot pixels | Hard (state over time) |
| Displacement damage | Permanent lattice defects â†’ dark current increase | Hard |
| Mechanical vibration | Motion blur (PSF) | Engine camera model |
| EMI | Periodic noise patterns | Medium |

## 3.7 PRNU â€” Per-Channel Analysis

**Confirmed**: PRNU is wavelength-dependent. Each channel has its own pattern due to:
1. CFA dye non-uniformity (thickness/concentration variations)
2. Wavelength-dependent photodiode QE non-uniformity
3. Angle-dependent PRNU is colour-dependent (SPIE)

| Model | Use Case | Cost |
|-------|----------|------|
| Single gain (current) | General visualisation | 1 hash/px |
| Per-channel PRNU | Scientific accuracy | 3 hashes/px |
| Spectral PRNU | Hyperspectral | N hashes/px |

---

# Part 4: Feasibility and Priority

## 4.1 Shader Feasibility Tiers

### Tier 1: Already Implemented âœ…
Photon shot noise, dark current + shot noise, DSNU, hot pixels, PRNU, read noise.

### Tier 2: Straightforward Additions ğŸ”§

| Element | LOE | Implementation |
|---------|-----|----------------|
| Bayer mosaic + MHC demosaic | Medium | 2 shader passes; 13 texel fetches for MHC |
| Vignetting (cosâ´Î¸) | Easy | Distance-based multiply |
| Lens distortion | Easy-Med | UV coordinate remapping |
| Chromatic aberration | Medium | Per-channel UV offsets |
| Quantisation | Trivial | `floor(v * levels) / levels` |
| Soft saturation | Easy | Exponential compression curve |
| Column FPN | Easy | 1D spatial hash per column |
| Per-channel PRNU | Easy | 3Ã— `rand_normal()` |
| Dead pixels | Trivial | Bernoulli + spatial seed â†’ 0 |
| White balance + CCM + gamma | Easy | Multiply, 3Ã—3 matmul, pow() |

### Tier 3: Complex but Feasible ğŸ”¶

| Element | Challenge |
|---------|-----------|
| 1/f noise | Temporal correlation â†’ persistent buffer |
| Temperature-dependent dark current | Arrhenius parameterisation |
| Pixel crosstalk | Nearest-neighbour kernel |
| Cosmic ray hits (single-pixel) | Low-probability high-energy events |
| RTS noise | Two-state Markov, persistent state |
| Full ISP chain | Many stages, each individually simple |

### Tier 4: Engine-Level or Impractical ğŸ”´
Full spectral rendering, cumulative radiation damage, atmospheric radiative transfer, multi-pixel cosmic ray tracks, lens flare/ghosts, spectral material textures.

## 4.2 Priority Ranking for Implementation

| # | Element | Impact | Effort | Rationale |
|---|---------|--------|--------|-----------|
| **1** | **Bayer + MHC demosaic** | â˜…â˜…â˜…â˜…â˜… | Med | Biggest single gap. Fundamentally changes noise character. |
| **2** | **Vignetting** | â˜…â˜…â˜…â˜… | Easy | Universal optical artifact. Immediately recognisable. |
| **3** | **Column FPN** | â˜…â˜…â˜…â˜… | Easy | Classic CMOS signature. Makes noise look "digital." |
| **4** | **Quantisation** | â˜…â˜…â˜… | Trivial | Visible in smooth gradients. One line of code. |
| **5** | **Per-channel PRNU** | â˜…â˜…â˜… | Easy | More realistic colour non-uniformity. |
| **6** | **Soft saturation** | â˜…â˜…â˜… | Easy | Realistic highlight roll-off. |
| **7** | **Dead pixels** | â˜…â˜… | Trivial | Complements existing hot pixels. |
| **8** | **ISP pipeline** | â˜…â˜…â˜…â˜… | Med | Makes output look like a real camera image. |

## 4.3 PRNU Interaction with Bayer

**Iteration 4 clarification**: In a real sensor, PRNU applies per-photosite â€” i.e., in the Bayer domain on scalar values. Each photosite has ONE quantum efficiency, applied to the ONE colour it sees through its filter. When we model per-channel PRNU in RGB space, we're approximating this correctly IF each channel's PRNU is independent. In Bayer domain, it would be even more correct: each pixel gets a single PRNU gain factor, but that factor depends on which colour filter covers it.

---

# Part 5: Integration Architecture

## 5.1 MATLAB Cross-Validation

```
MATLAB (ISETCam)                    Shader Pipeline
â”‚                                    â”‚
â”‚ Scene spectral radiance            â”‚ Rendered RGB
â”‚ â†’ Optics (spectral PSF)            â”‚ â†’ Bayer mosaic
â”‚ â†’ Sensor (spectral QE)             â”‚ â†’ PRNU
â”‚ â†’ Noise (shot, dark, read)         â”‚ â†’ Dark noise
â”‚ â†’ ADC                              â”‚ â†’ Shot noise
â”‚ â†’ ISP                              â”‚ â†’ Read noise
â”‚                                    â”‚ â†’ Demosaic + ISP
â”‚                                    â”‚
â””â”€â”€ Compare PTC curves â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Validation method**: Generate synthetic PTC from shader output at multiple exposure levels. Compare against MATLAB PTC and real sensor EMVA 1288 datasheets.

## 5.2 Game Engine Embedding

```
Custom Engine / Unity / Unreal
â”‚
â”œâ”€â”€ Render scene â†’ FBO
â”‚
â”œâ”€â”€ Post-processing chain:
â”‚   â”œâ”€â”€ [Optional] Bayer mosaic
â”‚   â”œâ”€â”€ Vignetting + distortion
â”‚   â”œâ”€â”€ PRNU (spatial seed)
â”‚   â”œâ”€â”€ Dark noise (spatial + temporal seed)
â”‚   â”œâ”€â”€ Shot noise (signal-dependent Poisson)
â”‚   â”œâ”€â”€ Read noise (Gaussian)
â”‚   â”œâ”€â”€ Column FPN (1D spatial seed)
â”‚   â”œâ”€â”€ Quantisation
â”‚   â”œâ”€â”€ [Optional] MHC demosaic
â”‚   â””â”€â”€ ISP (WB, CCM, gamma)
â”‚
â””â”€â”€ Display
```

**Portability**: The core noise math (PCG hash, distribution samplers, physical model) is identical in GLSL, HLSL, Metal, CUDA, and C. No engine-specific features needed.

## 5.3 Working in Electron Domain vs Normalised Domain

**Iteration 4 â€” Final Recommendation**:

Currently we work in [0, 1] normalised space. For physical accuracy, we should ideally convert to electron counts:

```
signal_electrons = signal_normalised Ã— FWC
```

Then apply noise in electron domain (where Poisson statistics are correct), then convert back:

```
signal_normalised = signal_electrons / FWC
```

This is important because Poisson noise depends on the absolute count, not normalised values. Our current approximation (`photonScale` parameter) simulates this by scaling before Poisson sampling, but working in true electron domain would make parameter correspondence to real sensor specs (from EMVA 1288 datasheets) direct and unambiguous.

---

# Part 6: Final Assessment â€” How Well Do Our Shaders Hold Up?

## 6.1 Against a Basic Camera Simulation

| Requirement | Coverage |
|-------------|----------|
| Shot noise statistics | âœ… Correct (Poisson) |
| Read noise statistics | âœ… Correct (Gaussian) |
| Dark current baseline | âœ… Correct |
| Dark current temporal noise | âœ… Correct (Poisson) |
| DSNU spatial pattern | âœ… Correct (spatial seed) |
| Hot pixels | âœ… Correct (Bernoulli + fixed) |
| PRNU gain variation | âœ… Correct (multiplicative) |
| **Verdict** | **~80% of basic noise physics covered** |

## 6.2 Against a Full Physical Simulation

| Gap | Impact | Priority |
|-----|--------|----------|
| No Bayer/demosaicing | **High** â€” wrong noise correlation structure | P1 |
| No vignetting | **High** â€” universal optical artifact missing | P2 |
| No column FPN | **Medium** â€” missing characteristic CMOS signature | P3 |
| No temperature dependence | **Medium** â€” limits dark current accuracy | P5+ |
| No per-channel PRNU | **Low-Medium** â€” subtle improvement | P5 |
| No ISP pipeline | **High** â€” output doesn't look like a "camera image" | P8 |
| No spectral rendering | Low (RGB sufficient for general use) | Tier 4 |

## 6.3 Self-Correction Summary Across All Iterations

| Claim | Original (Iter 1) | Corrected (Iter 2-4) |
|-------|-------------------|---------------------|
| Dark noise = dark current shot noise | âŒ | EMVA 1288: Ïƒ_d includes ALL temporal noise in darkness |
| CDS eliminates 1/f noise | âŒ | CDS suppresses partially; 1/f often remains dominant |
| Dark current doubles every 5.5-8Â°C | âš ï¸ | Range is 5-10Â°C depending on activation energy |
| PRNU is wavelength-independent | âŒ | PRNU is measurably wavelength-dependent per channel |
| Noise can be applied in RGB domain equally | âš ï¸ | Must apply in Bayer domain for correct spatial correlation |
| Hard clamp at saturation is correct | âŒ | Real sensors have soft saturation curve near FWC |
| Blooming is common | âš ï¸ | Modern CMOS has anti-blooming; blooming rare in practice |

---

*Document complete â€” 4 iterations of research and self-correction. 11 online research queries. Major topics covered: RGB-to-Bayer conversion and MHC demosaicing, dark noise taxonomy with EMVA 1288 definitions, Arrhenius dark current model, comprehensive physical sensor simulation inventory (17 noise/effect sources), cosmic ray rates, pixel crosstalk, RTS noise, PTC validation method, blooming physics, and integration architecture for MATLAB and game engines.*
